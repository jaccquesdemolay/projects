# -*- coding: utf-8 -*-
"""Task3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12W7Pi9hR2L9c5LCA1T1uw1w00Qq-DYEX
"""

#imports

import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split

#MLA Algorithms 
class LogisticRegression:
    def __init__(self, learning_rate=0.01, num_iterations=1000):
        self.learning_rate = learning_rate
        self.num_iterations = num_iterations
    
    def sigmoid(self, z):
        # sigmoid function to convert linear output into probabilities
        return 1 / (1 + np.exp(-z))
    
    def fit(self, X, y):
        # fit the logistic regression model to the training data
        self.X = X
        self.y = y.reshape(-1, 1) # convert to a column vector
        self.m, self.n = self.X.shape
        self.weights = np.zeros((self.n, 1)) # initialize weights to zeros
        self.bias = 0
        
        # gradient descent to minimize cost function
        for i in range(self.num_iterations):
            # forward propagation
            z = np.dot(self.X, self.weights) + self.bias
            A = self.sigmoid(z)
            
            # backward propagation
            dz = A - self.y
            dw = (1 / self.m) * np.dot(self.X.T, dz)
            db = (1 / self.m) * np.sum(dz)
            
            # update parameters
            self.weights -= self.learning_rate * dw
            self.bias -= self.learning_rate * db
    
    def predict(self, X):
        # predict labels for new data using the trained logistic regression model
        z = np.dot(X, self.weights) + self.bias
        A = self.sigmoid(z)
        return np.round(A).astype(int) # convert probabilities to binary labels
    
    def score(self, X, y):
        # calculate accuracy of the logistic regression model on the given test data
        y_pred = self.predict(X)
        return np.mean(y_pred == y.reshape(-1, 1))
      

class NaiveBayes:
    def fit(self, X, y):
        n_samples, n_features = X.shape
        self.classes = np.unique(y)
        n_classes = len(self.classes)
        
        # Calculate mean, variance, and prior probability for each class
        self.mean = np.zeros((n_classes, n_features))
        self.variance = np.zeros((n_classes, n_features))
        self.prior = np.zeros(n_classes)
        for idx, c in enumerate(self.classes):
            X_c = X[y == c]
            self.mean[idx, :] = X_c.mean(axis=0)
            self.variance[idx, :] = X_c.var(axis=0)
            self.prior[idx] = X_c.shape[0] / float(n_samples)

    def predict(self, X):
        # Calculate the posterior probability for each class
        posteriors = []
        for idx, c in enumerate(self.classes):
            prior = np.log(self.prior[idx])
            posterior = np.sum(np.log(self.probability_density_function(X, idx)), axis=1)
            posterior = prior + posterior
            posteriors.append(posterior)
        
        # Return the class with the highest posterior probability
        return self.classes[np.argmax(posteriors)]

    def probability_density_function(self, X, idx):
        # Calculate the probability density function for each feature
        mean = self.mean[idx]
        var = self.variance[idx]
        numerator = np.exp(-((X - mean)**2 / (2 * var)))
        denominator = np.sqrt(2 * np.pi * var)
        return numerator / denominator

# Read the dataframe
df = pd.read_csv('covid_data.csv')
df

# Rename headers
header_names=['age', 'sex', 'fever', 'cough', 'fatigue', 'short_breathe', 'body_aches', 'headache', 'smell_taste_loss', 'covid']
df = pd.read_csv('covid_data.csv',header=None, skiprows=1,names=header_names)
df

#Prints information about the dataframe
df.info()

#Check and sum all null data
df.isnull().sum

#Check and sum all duplicated information
df.duplicated().sum()

#Delete all of the duplicated information and add the new dataframe to a new variable
cv = df.drop_duplicates()
cv

# Describe the dataframe to check the necessity to treat the information
cv.describe()

# Print the quantity of unique data in each column
for c in cv.columns:
  print(f"{c}: {cv[c].nunique()}")

# Drop covid and add the other columns to be used on sklearn
X = cv.drop('covid', axis = 1)
y = cv['covid']
y

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#LogisticRegression
log = LogisticRegression()

#training
log.fit(X_train.values, y_train.values)

# score accuracy of the trained sets
log.score(X_train.values, y_train.values)

# score accuracy of the testing sets
log.score(X_test.values, y_test.values)

# Naive Bayes
log2 = NaiveBayes()

#training
log2.fit(X_train.values, y_train.values)

# Asking the user to input its data

age = (int(input("Type your age: ")))

sex = (int(input("Type your sex (0 for Male / 1 for Female): ")))

fever = (int(input("Type if you have Fever (0 for No / 1 for Yes): ")))
cough = (int(input("Type if you have Cough (0 for No / 1 for Yes): ")))
fatigue = (int(input("Type if you have Fatigue (0 for No / 1 for Yes): ")))
short_breathe = (int(input("Type if you have Shortness of breath (0 for No / 1 for Yes): ")))
body_aches = (int(input("Type if you have Body aches (0 for No / 1 for Yes): ")))
headache = (int(input("Type if you have Headache (0 for No / 1 for Yes): ")))
smell_taste_loss = (int(input("Type if you have Loss of smell or taste (0 for No / 1 for Yes): ")))

# Make a prediction using the trained model
data_input = [[age, sex, fever, cough, fatigue, short_breathe, body_aches, headache, smell_taste_loss]]
data_input_np = np.array(data_input)
data_input_framed = pd.DataFrame(data_input_np)

predictio1n = log.predict(data_input_framed)

# Print the prediction
if predictio1n[0] == 1:
    print("Using LogisticRegression prediction, you may have COVID-19. Please consult a healthcare professional.")
else:
    print("Using LogisticRegression prediction, it is unlikely that you have COVID-19, but please continue to monitor your symptoms.")

#Makes the prediction using the Naibe Bayes
predictio2n = log2.predict(data_input_framed)

# Print the prediction
if predictio2n == 1:
    print("Using Naive-Bayes prediction, you may have COVID-19. Please consult a healthcare professional.")
else:
    print("Using Naive-Bayes prediction, it is unlikely that you have COVID-19, but please continue to monitor your symptoms.")